{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroinformatics: Using Python for literature searches\n",
    "\n",
    "### Guest content & lecture by Monique Surles-Zeigler\n",
    "\n",
    "In this notebook, you will learn to:\n",
    "* Identify the conceptual and technical tools used to conduct informatics research (e.g. APIs, ontologies, bioentrez, BLAST)\n",
    "* Identify the structure and use of json format\n",
    "* Define MESH terms & describe their role in informatics research\n",
    "* Explain the role and importance of informatics research\n",
    "* Conduct a pubmed search using bioentrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We'll need many new packages that aren't in our DataHub for today's lab. To get everything setup, run our setup script below.\n",
    "\n",
    "<mark>This will take a few minutes. Please restart the kernel when it is finished.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and update packages\n",
    "# More information about installing packages - https://packaging.python.org/en/latest/tutorials/installing-packages/\n",
    "! pip install xmljson\n",
    "! pip install xmltodict\n",
    "! pip install Biopython\n",
    "! pip install myst-nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the loaded libraries from the installed programs. The `import X from` line imports the module X, and creates references to all public objects defined by that module in the current namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     Type        Data/Info\n",
      "----------------------------------\n",
      "Entrez       module      <module 'Bio.Entrez' from<...>/Bio/Entrez/__init__.py'>\n",
      "deepcopy     function    <function deepcopy at 0x7f884bad3510>\n",
      "fromstring   function    <function XML at 0x7f884e78e7b8>\n",
      "json         module      <module 'json' from '/Use<...>hon3.7/json/__init__.py'>\n",
      "l1           list        n=3\n",
      "l2           list        n=3\n",
      "l3           list        n=3\n",
      "pd           module      <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n",
      "product      type        <class 'itertools.product'>\n",
      "time         module      <module 'time' (built-in)>\n",
      "urllib       module      <module 'urllib' from '/U<...>n3.7/urllib/__init__.py'>\n",
      "xmltodict    module      <module 'xmltodict' from <...>e-packages/xmltodict.py'>\n",
      "yh           Yahoo       <xmljson.Yahoo object at 0x7f884e770240>\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez \n",
    "\n",
    "from xmljson import yahoo as yh\n",
    "from xml.etree.ElementTree import fromstring\n",
    "import xmltodict\n",
    "\n",
    "import urllib\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# Show list of imported packages\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review all of the installed packages and version \n",
    "! pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing NCBI databases with Biopython\n",
    "**Biopython** is a set of freely available tools for biological computation written in Python. It contains a collection of python modules to search to deal with DNA, RNA & protein sequence operations such as reverse complementing of a DNA string, finding motifs in protein sequences, etc.\n",
    "\n",
    "Bio.Entrez is the module within the BioPython package that provides code to access NCBI over the World Wide Web to retrieve various sorts of information. This module provides a number of functions which will return the data as a handle object. This is the standard interface used in Python for reading data from a file and provides methods or offers iteration over the contents line by line.\n",
    "\n",
    "### Bio.Entrez is not the only sub-module in Biopython. [Other packages include](https://biopython.org/docs/1.75/api/index.html):\n",
    "- Bio.GEO - Access to data from the Gene Expression Omibus database.\n",
    "- Bio.KEGG - Access to data from the KEGG database.\n",
    "- Bio.motifs - Access to tools for sequence motif analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in Bio.entrez\n",
    "\n",
    "Bio.Entrez has a ton of different functions. We'll use a few (highlighted) in our notebook today . Read more about these functions on [the website](https://www.ncbi.nlm.nih.gov/books/NBK25499/).\n",
    "\n",
    "The primary functions we'll use today are:\n",
    "\n",
    "- **eInfo** - Provides the number of records indexed in each field of a given database, the date of the last update of the database, and the available links from the database to other Entrez databases.\n",
    "- **eSearch** - Responds to a text query with the list of matching **Entrez Unique Identifier (UIDs)** in a given database (for later use in ESummary, EFetch or ELink), along with the term translations of the query.\n",
    "- **efetch** - Retrieves records in the requested format from a list of one or more primary IDs or from the userâ€™s environment\n",
    "- **read** - Parses the XML results returned by any of the above functions.\n",
    "\n",
    "**Note**: Entrez will request your email so that it can keep track of its users. Always provide your email with `Entrez.email = 'your@email.com`.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 1**: Create a <b>function</b> called `get_info` that requests your email as a string, and assigns it to the variable name `Entrez.email`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned in the slides, the BioEntrez package provides access to multiple biomedical databases. <mark>Below, we'll access the Entrez API to search for a list of databases in Bio.Entrez.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a variable (e.g.handle) where the results will be stored \n",
    "# pass within the Entrez.einfo() function.\n",
    "handle = Entrez.einfo()\n",
    "record = Entrez.read(handle)\n",
    "print (record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 2**: Assign the output of `Entrez.einfo()` to a variable called `handle`. Within  the `einfo` function, search for information within the pubmed database (as a string) with the variable 'db'. There's additional information on how to do this [here](http://biopython.org/DIST/docs/tutorial/Tutorial.html#sec145).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 3**: Pull out information from the dictionary about \n",
    "1. Paper counts\n",
    "2. Field list \n",
    "3. How many MESH terms are associated with the papers?\n",
    "4. That other information can you pull it?\n",
    "5. Can you make the output more readable?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3 - code block: Pull out information from the dictionary here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The product function\n",
    "Let's learn about a new function: `product()`, which we imported above from `itertools`. Documentation on this function can be found at https://docs.python.org/3/library/itertools.html. \n",
    "Multiple lists can be added to product and it returns every possible combination of values but remember that is an iterator (traverse through all values), so the contents is not output by `print()`.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #4**: Let's test product out in the sample below\n",
    "```{python}\n",
    "l1 = ['a', 'b', 'c']\n",
    "l2 = ['X', 'Y', 'Z']\n",
    "l3 = [1, 2, 3]\n",
    "p = product(l1, l2, l3)\n",
    "```\n",
    "\n",
    "1. What happens when you print p?\n",
    "2. What type of object is p (e.g. list, dictionary, other)?\n",
    "3. Can you figure out another way to view the output of p?\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #5**: The goal of this task is to create a function that takes in multiple lists (sound familiar?), and join combinations of the lists together. \n",
    "\n",
    "Complete the function below by completing the following steps:\n",
    "\n",
    "1. Add the 3 lists (brain_region, cell_type, method) to the itertools function, product(). \n",
    "2. Iterate over the list created in step 1, preferably through list comprehension. Use the built-in join() function to join each element together with the string \" AND \"\n",
    "3. Return the results from step 2 \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 - Code block. Complete the function here\n",
    "def comb_list(brain_region, cell_type, method):\n",
    "    '''iterate over terms given - in this case brain region, cell type and method'''\n",
    "    # 1. Add the 3 list to the itertools function, product(). This function returns every possible combination of values from a group of lists.\n",
    "    # 2. Iterate over the list created in step 1, preferably through list comprehension. Use the built-in join() function to join each element together with the string \" AND \"\n",
    "    # 3. Return the results from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to be feed into the comb_list() function\n",
    "brain_region = [\"hippocampus\"]\n",
    "\n",
    "cell_type = [\"CA1 pyramidal cell\", \"CA2 pyramidal cell\", \"CA3 pyramidal cell\", \"CA4 Pyramidal Cell\", \"Dentate Gyrus Granule Cell\", \"Dentate Gyrus Basket Cell\", \"CA1 Basket Cell\"]\n",
    "\n",
    "method = [\"rna seq* \",\"microarray\",\"in situ hybridization\", \"polymerase chain reaction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #6**: Now, use the `comb_term()` function that you created to create all combinations of the three list above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 6 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " \n",
    "**Task #7**: Create a script to search PubMed with the search terms created above (Task 6).\n",
    "Previously, we used the script below \n",
    "\n",
    "```{python}\n",
    "handle = Entrez.einfo()\n",
    "record = Entrez.read(handle)\n",
    "print (record)\n",
    "```\n",
    "\n",
    "This script allowed us to \n",
    "- To extract information (einfo)from the Entrez databases and declare a variable (e.g.handle) where the results will be stored \n",
    "- Then parse the results returned by einfo()\n",
    "\n",
    "Now, let's use `esearch()` to search for papers in Pubmed within Entrez, read those results and return the output\n",
    "More information about esearch and how to use it is [here](https://biopython-tutorial.readthedocs.io/en/latest/notebooks/09%20-%20Accessing%20NCBIs%20Entrez%20databases.html)\n",
    "\n",
    "For this search we will use the search terms created above search for papers within PubMed. Let's try it below.\n",
    "\n",
    "<mark>**Hint**: Remember, we need to search the terms above within the pubmed database. [more help here](https://dataguide.nlm.nih.gov/edirect/esearch.html)  .</mark>\n",
    "\n",
    "What is the output? Is there a better way to view all of the results?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 7 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #8**: Create the function to search PubMed `get_abstract` with the search terms created above.\n",
    "Previously, we used the script below to find out more about the databases within Entrez\n",
    "\n",
    "```{python}\n",
    "handle = Entrez.einfo()\n",
    "record = Entrez.read(handle)\n",
    "print (record)\n",
    "```\n",
    "\n",
    "Then, in the Task above (Task 7), we used esearch to search the Pubmed database and retrieve PubMed IDs for our search terms.\n",
    "\n",
    "\n",
    "Now, let's use `efetch()` to retreive the abstract from Pubmed within Entrez, read those results and return the output\n",
    "More information about esearch and how to use it is here - \n",
    "    - Pubmed databaase, use pmid as an id for all papers and load all abstract\n",
    "\n",
    "<mark>**Hint**: Remember, we need to some or all of the PubMed IDs from Task 7. [more help here](https://dataguide.nlm.nih.gov/edirect/efetch.html)</mark>\n",
    "\n",
    "Don't forget to use your function. How does the results look? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 8 - code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check for Task 8 - after you have attempted to complete. \n",
    "<br></br>\n",
    "\n",
    "<details>\n",
    "    <summary>Click once on <font color=\"pink\"><b>this text</b></font> to hide/unhide the answer!</summary>\n",
    "  \n",
    "```{python}\n",
    "def get_abstract(term_ids):\n",
    "    fetch_handle = Entrez.efetch(db='pubmed', id=term_ids, retmode='xml', retmax=4000, rettype='abstract')\n",
    "    return fetch_handle.read()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #9**: Now for a bit of a clean up step. It is a bit difficult to properly read through the current output. Let's change the format of the text with the code below.\n",
    "\n",
    "```{python}\n",
    "y_abstracts = yh.data(fromstring(abstracts))\n",
    "```\n",
    "<mark>**Hint**: Add this line of code to the script from Task 8</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9- Code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "***Task #10***: Exploratory task\n",
    "- Have fun! Or as much as you can stand. \n",
    "Now, Let's put every thing together. This exercise is for you to see what the data looks like and how to extract data from the nested data structures (e.g., list, dictionaries,etc) \n",
    "    - Explore and try to extract all or some of the data. It may help to only look at a few abstracts\n",
    "        -  Can you get to the PubMed Article? <mark>(Hint)- Remember, to check the datatypes (`type()`) to help you <mark>\n",
    "        If so, delve deeper and see if you can get the \n",
    "        1. Article Title\n",
    "        2. Journal Title\n",
    "        3. Author List\n",
    "        4. pmc id\n",
    "        5. doi \n",
    "        6. Mesh headings\n",
    "        7. Article date\n",
    "    - Now, can you package this all in a funtion called findformat_abstract(), that takes in the search terms and returns the abstracts\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10 - Code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use findformat script\n",
    "Below, we'll use a script (`findformat.ipynb`). Take a look a close look at this function -- what is it doing? How is it different than your code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run findformat.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all abstracts   \n",
    "new_abstracts = {}\n",
    "gene_abstracts = findformat_abstract(terms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only get the abstracts with pmc ids\n",
    "pmc_abstracts = {k: v for k, v in gene_abstracts.items() if len(v['PMC']) > 0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way to make a copy of dictionary, as a backup in case\n",
    "#  Deepcopy () copies all the elements of an object as well as the memory location that contains data rather than containing the data itself.\n",
    "gene_abstract_cp = deepcopy(gene_abstracts)\n",
    "pmc_abstract_cp = deepcopy(pmc_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original count', len(gene_abstracts))\n",
    "print('PMC:', len(pmc_abstracts))\n",
    "print('difference =', len(gene_abstracts)-len(pmc_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The length of `pmc_abstracts` is less than that of `gene_abstract`. Why is that?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results as a dataframe\n",
    "It's difficult to visually parse dictionaries. Thankfully we have another tool at our disposal: pandas.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Task 12**: Turn `gene_abstracts` into a pandas dataframe called `gene_abstract_df`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 12: code block - Turn gene_abstract into a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, it would make a lot more sense if each paper had its own row -- that's how we typically conceptualize dataframes, with each row as a different observation, patient, cell, etc. We can **transpose** the dataframe using the [`transpose`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html) (or `T` for short) method.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 13**: Using the `iloc` method, view *just* the first abstract.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 13 - code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run this bit of code to get the pmc papers\n",
    "'''Let's make a copy of pmc_abstract'''\n",
    "pmc_abstract = deepcopy(pmc_abstracts)\n",
    "'''find open access files, extract results and methods sections and convert xml to json format'''\n",
    "\n",
    "for k, v in pmc_abstracts.items():\n",
    "    pmc = pmc_abstracts[k]['PMC']\n",
    "    if len(pmc)>0:\n",
    "        pmc_idno =(s.strip('PMC') for s in v['PMC'])\n",
    "        #confirm that file is Open Access\n",
    "        try_this = pmc_abstract[k]['PMC']\n",
    "        find_pdf = \"https://www.ncbi.nlm.nih.gov/pmc/utils/oa/oa.fcgi?id={}\".format(*try_this)\n",
    "        #get xml record\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi?verb=GetRecord&identifier=oai:pubmedcentral.nih.gov:{}&metadataPrefix=pmc\".format(*pmc_idno)\n",
    "        pmc_abstract[k]['OA web address'] = url\n",
    "        with urllib.request.urlopen(find_pdf) as response:\n",
    "            the_file = response.read().decode('utf-8')\n",
    "            dict_file = xmltodict.parse(the_file)\n",
    "\n",
    "            try:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['records']['record']['link']['@href']\n",
    "            except KeyError:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['error']['#text']\n",
    "            except TypeError:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['records']['record']\n",
    "\n",
    "        with urllib.request.urlopen(url) as responsec:\n",
    "            the_filec = responsec.read().decode('utf-8')\n",
    "            dict_filec = xmltodict.parse(the_filec)\n",
    "            \n",
    "            try:\n",
    "                #print (dict_filec['OAI-PMH']['GetRecord'].keys())\n",
    "                data_level = dict_filec['OAI-PMH']['GetRecord']['record']['metadata']['article']['body']['sec']\n",
    "                print (data_level)\n",
    "            except KeyError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task #14**: Exploratory task\n",
    "- Have fun...again! I know, it is too much fun...run the code below and try to extract the methods and results sections from each paper or a subset of papers\n",
    "\n",
    "I know it seems overwheming but the code is listed below. let's just see if you can filter the text. \n",
    "  \n",
    "Can you extract the methods and results sections? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 14 - Beginning code - Now explore...\n",
    "\n",
    "#Let's make a copy of pmc_abstract'''\n",
    "pmc_abstract = deepcopy(pmc_abstracts)\n",
    "'''find open access files, extract results and methods sections and convert xml to json format'''\n",
    "\n",
    "for k, v in pmc_abstracts.items():\n",
    "    pmc = pmc_abstracts[k]['PMC']\n",
    "    if len(pmc)>0:\n",
    "        pmc_idno =(s.strip('PMC') for s in v['PMC'])\n",
    "        #confirm that file is Open Access\n",
    "        try_this = pmc_abstract[k]['PMC']\n",
    "        find_pdf = \"https://www.ncbi.nlm.nih.gov/pmc/utils/oa/oa.fcgi?id={}\".format(*try_this)\n",
    "        #get xml record\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi?verb=GetRecord&identifier=oai:pubmedcentral.nih.gov:{}&metadataPrefix=pmc\".format(*pmc_idno)\n",
    "        pmc_abstract[k]['OA web address'] = url\n",
    "        with urllib.request.urlopen(find_pdf) as response:\n",
    "            the_file = response.read().decode('utf-8')\n",
    "            dict_file = xmltodict.parse(the_file)\n",
    "\n",
    "            try:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['records']['record']['link']['@href']\n",
    "            except KeyError:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['error']['#text']\n",
    "            except TypeError:\n",
    "                pmc_abstract['ftp_record'] = dict_file['OA']['records']['record']\n",
    "\n",
    "        with urllib.request.urlopen(url) as responsec:\n",
    "            the_filec = responsec.read().decode('utf-8')\n",
    "            dict_filec = xmltodict.parse(the_filec)\n",
    "            \n",
    "            try:\n",
    "                #print (dict_filec['OAI-PMH']['GetRecord'].keys())\n",
    "                data_level = dict_filec['OAI-PMH']['GetRecord']['record']['metadata']['article']['body']['sec']\n",
    "                print (data_level)\n",
    "            except KeyError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll use a script (`getTexts.ipynb`). Take a look a close look at this function -- what is it doing? How is it different than your code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run getTexts.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format the Methods and Results section \n",
    "g_updated_records = getTexts(gene_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make another copy of the file since a lot of information is in here.\n",
    "pmc_papers = deepcopy(g_updated_records)\n",
    "pmc_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results as a json & excel file\n",
    "\n",
    "Below, we'll save our findings as both a json and an Excel file. **JavaScript Object Notation (JSON)** is a standardized format commonly used to transfer data between systems and used by a lot of databases and APIs. \n",
    "Like Python dictionaries, it represents objects as name/value pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file as a json file\n",
    "with open('g_updated_records.json', 'w') as outfile:        \n",
    "    json.dump(g_updated_records, outfile)\n",
    "    \n",
    "#read in json file    \n",
    "with open('g_updated_records.json', 'r') as newfile:\n",
    "    g_updated_records = json.load(newfile)\n",
    "    \n",
    "#save file to an excel file - save file as pandas dataframe, save to excel\n",
    "df_updated_records = dp = pd.DataFrame(gene_abstracts).T\n",
    "g_updated_records.to_excel('g_updated_records.json.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
